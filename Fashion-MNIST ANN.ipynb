{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcxaNH+zpz8+cX6jcZKuSG"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "Challenge: The Fashion-MNIST dataset\n",
        "\n",
        "Ion Petre FoundML_course_assignments\n",
        "/FML2w4_deep_learning.ipynb\n",
        "https://github.com/ionpetre/FoundML_course_assignments/blob/main/FML2w4_deep_learning.ipynb\n",
        "\n",
        "@author: jarno\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "from keras import models\n",
        "from keras import layers\n",
        "import random\n",
        "\n",
        "(X_train_valid, y_train_valid), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "print('We have %2d training pictures and %2d test pictures.' % (X_train_valid.shape[0],X_test.shape[0]))\n",
        "print('Each picture is of size (%2d,%2d)' % (X_train_valid.shape[1], X_train_valid.shape[2]))\n",
        "\n",
        "# =============================================================================\n",
        "# Data preprocessing\n",
        "# The data must be preprocessed before training the network.\n",
        "# If you inspect the first image in the training set,\n",
        "# you will see that the pixel values fall in the range of 0 to 255:\n",
        "# =============================================================================\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(X_train_valid[0])\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Scale the data into [0,1] by dividing to 255\n",
        "\n",
        "X_train_valid_std = X_train_valid/255\n",
        "X_test_std  = X_test/255\n",
        "# Display some images\n",
        "\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "plt.figure(figsize=(20,12))\n",
        "for i in range(15): # i start from zero\n",
        "    plt.subplot(3,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    j = random.randint(2,40)\n",
        "    plt.imshow(X_train_valid_std[(i+1)*j])\n",
        "    plt.xlabel(class_names[int(y_train_valid[(i+1)*j])], fontsize=30)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# Is the dataset balanced?\n",
        "\n",
        "y_train_valid_count = np.unique(y_train_valid, return_counts=True)\n",
        "df_y_train_valid = pd.DataFrame({'Label':y_train_valid_count[0], 'Count':y_train_valid_count[1]})\n",
        "df_y_train_valid\n",
        "\n",
        "# A: YES!\n",
        "\n",
        "# Train - validation split\n",
        "\n",
        "X_train_std, X_valid_std, y_train, y_valid = train_test_split(\n",
        "    X_train_valid_std,\n",
        "    y_train_valid,\n",
        "    test_size=0.2,\n",
        "    random_state=150,\n",
        "    stratify=y_train_valid,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Check the result of the data split\n",
        "\n",
        "print('# of training images:', X_train_std.shape[0])\n",
        "print('# of validation images:', X_valid_std.shape[0])\n",
        "print(\"Note the shape of the data (1 color channel, dosen't show):\", X_train_std.shape)\n",
        "\n",
        "\n",
        "\n",
        "# Encode the labels from numerical to categorical\n",
        "\n",
        "#from keras.utils import to_categorical\n",
        "\n",
        "y_train_cat = to_categorical(y_train, num_classes=10)\n",
        "y_valid_cat = to_categorical(y_valid, num_classes=10)\n",
        "y_test_cat = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "\n",
        "# Train an ANN model with an input \"Flatten\" layer of shape (28, 28, 1), accounting for the 1 color channels,\n",
        "#       followed by 3 layers of size 128/64/32, followed by an output layer of a suitable size.\n",
        "# Choose 'relu' for the activation function of the hidden layers, and a suitable activation for the output layer.\n",
        "\n",
        "\n",
        "ANNmodel = models.Sequential([\n",
        "    layers.Flatten(input_shape=(28, 28, 1)),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax'),\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "# Compile the model using the Adam optimizer with learning rate 1e-3\n",
        "#       and as metrics CategoricalAccuracy and TruePositives.\n",
        "# Use as the loss function CategoricalCrossentropy()\n",
        "\n",
        "\n",
        "ANNmodel.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=[tf.keras.metrics.CategoricalAccuracy(),\n",
        "             tf.keras.metrics.TruePositives(),\n",
        "            ],\n",
        ")\n",
        "\n",
        "ANNmodel.summary()\n",
        "\n",
        "\n",
        "# We reset all variables implicitly instantiated by Keras/tensorflow\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "\n",
        "# This callback will stop the training when there is no improvement in the loss\n",
        "#      for ten consecutive epochs.\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n",
        "\n",
        "# Fit the model by specifying the number of epochs and the batch size\n",
        "# We also indicate the validation data so we can collect the evolution\n",
        "#      of the metrics through the epochs, both on train, as well as on validation.\n",
        "\n",
        "ANN_fit_history = ANNmodel.fit(X_train_std,\n",
        "                               y_train_cat,\n",
        "                               epochs=300,\n",
        "                               batch_size=128,\n",
        "                               callbacks=[callback],\n",
        "                               validation_data=(X_valid_std, y_valid_cat)\n",
        "                              )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "history_dict = ANN_fit_history.history\n",
        "print(history_dict.keys())\n",
        "\n",
        "# Plot the evolution of the loss and the accuracy throughout the epochs\n",
        "# This is useful to find over-fitting and decide on early stopping of the training.\n",
        "\n",
        "#import matplotlib.pyplot as plt\n",
        "\n",
        "train_loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "train_acc = history_dict['categorical_accuracy']\n",
        "val_acc = history_dict['val_categorical_accuracy']\n",
        "train_tp = np.array(history_dict['true_positives']) / X_train_std.shape[0]\n",
        "val_tp = np.array(history_dict['val_true_positives']) / X_valid_std.shape[0]\n",
        "epochs = range(1, len(train_loss) + 1)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(20, 5))\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.plot(epochs, train_loss, 'b', label='Training cat. cross-entropy')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation cat. cross-entropy')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "plt.plot(epochs, train_acc, 'b', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Categorical accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "plt.plot(epochs, train_tp, 'b', label='Training TP')\n",
        "plt.plot(epochs, val_tp, 'r', label='Validation TP')\n",
        "plt.title('Training and validation true positives')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('True positives')\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# Use the model to predict in the form of a 10-class probability distribution\n",
        "\n",
        "\n",
        "\n",
        "y_train_prob = ANNmodel.predict(X_train_std)\n",
        "\n",
        "# Select the most likely class\n",
        "y_train_pred=np.argmax(y_train_prob, axis=1)\n",
        "\n",
        "print(\"\\n The classification results on the train data:\")\n",
        "print(classification_report(y_train,y_train_pred))\n",
        "print(\"Confusion matrix (train data):\\n\", confusion_matrix(y_train,y_train_pred))\n",
        "\n",
        "\n",
        "# The classification results for the validation data\n",
        "\n",
        "\n",
        "y_valid_prob = ANNmodel.predict(X_valid_std)\n",
        "y_valid_pred=np.argmax(y_valid_prob, axis=1)\n",
        "print(\"\\n The classification results on the validation data:\")\n",
        "print(classification_report(y_valid,y_valid_pred))\n",
        "print(\"Confusion matrix (validation data):\\n\", confusion_matrix(y_valid,y_valid_pred))\n",
        "print(\"Confusion matrix (validation data):\\n\", np.round(confusion_matrix(y_valid,y_valid_pred)/12))\n",
        "print(\"Confusion matrix (validation data):\\n\", np.round(confusion_matrix(y_valid,y_valid_pred)/12).astype(int))\n",
        "\n",
        "\n",
        "\n",
        "# Plot the first X validation images, their predicted labels, and the true labels in parenthesis.\n",
        "# Color correct predictions in blue and incorrect predictions in red.\n",
        "\n",
        "\n",
        "def plot_image(i, predictions_array, true_label, img):\n",
        "    true_label, img = int(true_label[i]), img[i]\n",
        "    plt.grid(False)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(img)\n",
        "\n",
        "    predicted_label = np.argmax(predictions_array)\n",
        "    if predicted_label == true_label:\n",
        "        color = 'blue'\n",
        "    else:\n",
        "        color = 'red'\n",
        "\n",
        "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "                                100*np.max(predictions_array),\n",
        "                                class_names[true_label]),\n",
        "                                color=color, fontsize=10, loc='left')\n",
        "\n",
        "def plot_value_array(i, predictions_array, true_label):\n",
        "    true_label = int(true_label[i])\n",
        "    plt.grid(False)\n",
        "    plt.xticks(range(10))\n",
        "    plt.yticks([])\n",
        "    thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
        "    plt.ylim([0, 1])\n",
        "    predicted_label = np.argmax(predictions_array)\n",
        "\n",
        "    thisplot[predicted_label].set_color('red')\n",
        "    thisplot[true_label].set_color('blue')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "num_rows = 3\n",
        "num_cols = 3\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize=(3*2*num_cols, 2*num_rows))\n",
        "\n",
        "for i in range(num_images):\n",
        "    j = random.randint(4, 20)\n",
        "    plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "    plot_image(i*j, y_valid_prob[i*j], y_valid, X_valid_std)\n",
        "    plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
        "    plot_value_array(i*j, y_valid_prob[i*j], y_valid)\n",
        "    plt.xticks(range(10), class_names, rotation=90)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2r3uFBbrqLB1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}