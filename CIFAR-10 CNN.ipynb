{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJxOnv4u3o6PB/8OfL0Ma6"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbSXh63QnXq_"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "\n",
        "Challenge: The CIFAR-10 dataset\n",
        "\n",
        "Ion Petre FoundML_course_assignments\n",
        "/FML2w5_cnn.ipynb\n",
        "https://github.com/ionpetre/FoundML_course_assignments/blob/main/FML2w5_cnn.ipynb\n",
        "\n",
        "@author: jarno\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "from keras import models\n",
        "from keras import layers\n",
        "import random\n",
        "\n",
        "(X_train_valid, y_train_valid), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "print('We have %2d training pictures and %2d test pictures.' % (X_train_valid.shape[0],X_test.shape[0]))\n",
        "print('Each picture is of size (%2d,%2d,%2d)' % (X_train_valid.shape[1], X_train_valid.shape[2], X_train_valid.shape[3]))\n",
        "\n",
        "\n",
        "# Scale the data into [0,1] by dividing to 255\n",
        "\n",
        "X_train_valid_std = X_train_valid/255\n",
        "X_test_std  = X_test/255\n",
        "\n",
        "\n",
        "# Display some images\n",
        "\n",
        "class_names = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n",
        "\n",
        "\n",
        "plt.figure(figsize=(20,12))\n",
        "for i in range(15): # i start from zero\n",
        "    plt.subplot(3,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    j = random.randint(2,40)\n",
        "    plt.imshow(X_train_valid_std[(i+1)*j])\n",
        "    plt.xlabel(class_names[int(y_train_valid[(i+1)*j])], fontsize=30)\n",
        "plt.show()\n",
        "\n",
        "# Is the dataset balanced?\n",
        "\n",
        "y_train_valid_count = np.unique(y_train_valid, return_counts=True)\n",
        "df_y_train_valid = pd.DataFrame({'Label':y_train_valid_count[0], 'Count':y_train_valid_count[1]})\n",
        "df_y_train_valid\n",
        "\n",
        "# A: YES!\n",
        "# Train - validation split\n",
        "\n",
        "X_train_std, X_valid_std, y_train, y_valid = train_test_split(\n",
        "    X_train_valid_std,\n",
        "    y_train_valid,\n",
        "    test_size=0.2, #validation size\n",
        "    random_state=150,\n",
        "    stratify=y_train_valid,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Check the result of the data split\n",
        "\n",
        "print('# of training images:', X_train_std.shape[0])\n",
        "print('# of validation images:', X_valid_std.shape[0])\n",
        "print(\"Note the shape of the data (3 color channels):\", X_train_std.shape)\n",
        "\n",
        "\n",
        "# Encode the labels from numerical to categorical\n",
        "\n",
        "#from keras.utils import to_categorical\n",
        "\n",
        "y_train_cat = to_categorical(y_train, num_classes=10)\n",
        "y_valid_cat = to_categorical(y_valid, num_classes=10)\n",
        "y_test_cat = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "\n",
        "# Train an ANN model with an input \"Flatten\" layer of shape (32, 32, 3), accounting for the 3 color channels,\n",
        "#       followed by 3 layers of size 128/64/32, followed by an output layer of a suitable size.\n",
        "# Choose 'relu' for the activation function of the hidden layers, and a suitable activation for the output layer.\n",
        "\n",
        "\n",
        "PETREmodel = models.Sequential([\n",
        "    layers.Conv2D(filters=32,\n",
        "                  kernel_size=(3, 3),\n",
        "                  strides=(1,1),\n",
        "                  padding='same',\n",
        "                  activation='relu',\n",
        "                  input_shape=X_train_std.shape[1:]  #(32,32,3)\n",
        "                 ),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(filters=32,\n",
        "                  kernel_size=(3, 3),\n",
        "                  strides=(1,1),\n",
        "                  padding='same',\n",
        "                  activation='relu'\n",
        "                 ),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2),strides=2),\n",
        "    layers.Dropout(0.25),\n",
        "    layers.Conv2D(filters=64,\n",
        "                  kernel_size=(3, 3),\n",
        "                  strides=(1,1),\n",
        "                  padding='same',\n",
        "                  activation='relu'  #(32,32,3)\n",
        "                 ),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(filters=64,\n",
        "                  kernel_size=(3, 3),\n",
        "                  strides=(1,1),\n",
        "                  padding='same',\n",
        "                  activation='relu'\n",
        "                 ),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2),strides=2),\n",
        "    layers.Dropout(0.25),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(units=64, activation='relu'),\n",
        "    layers.Dropout(0.25),\n",
        "    layers.Dense(units=10, activation = 'softmax')\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Compile the model using the Adam optimizer with learning rate 1e-3\n",
        "#       and as metrics CategoricalAccuracy and TruePositives.\n",
        "# Use as the loss function CategoricalCrossentropy()\n",
        "\n",
        "\n",
        "my_metrics = [tf.keras.metrics.CategoricalAccuracy(),\n",
        "              tf.keras.metrics.TruePositives(),\n",
        "              ]\n",
        "\n",
        "PETREmodel.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=my_metrics,\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "PETREmodel.summary()\n",
        "\n",
        "\n",
        "# We reset all variables implicitly instantiated by Keras/tensorflow\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "\n",
        "\n",
        "# This callback will stop the training when there is no improvement in the loss\n",
        "#      for three consecutive epochs.\n",
        "callback_loss_patience = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
        "\n",
        "# Fit the model by specifying the number of epochs and the batch size\n",
        "# We also indicate the validation data so we can collect the evolution\n",
        "#      of the metrics through the epochs, both on train, as well as on validation.\n",
        "\n",
        "PETRE_fit_history = PETREmodel.fit(X_train_std,\n",
        "                               y_train_cat,\n",
        "                               epochs=100,\n",
        "                               batch_size=500,\n",
        "                               callbacks=[callback_loss_patience],\n",
        "                               validation_data=(X_valid_std, y_valid_cat)\n",
        "                              )\n",
        "\n",
        "\n",
        "# Plot the evolution of the loss and the accuracy throughout the epochs\n",
        "# This is useful to find over-fitting and decide on early stopping of the training.\n",
        "def plot_train_history(history_dict):\n",
        "\n",
        "  print(history_dict.keys())\n",
        "\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "  train_loss = history_dict['loss']\n",
        "  val_loss = history_dict['val_loss']\n",
        "  train_acc = history_dict['categorical_accuracy']\n",
        "  val_acc = history_dict['val_categorical_accuracy']\n",
        "  train_tp = np.array(history_dict['true_positives']) / X_train_std.shape[0]\n",
        "  val_tp = np.array(history_dict['val_true_positives']) / X_valid_std.shape[0]\n",
        "  epochs = range(1, len(train_loss) + 1)\n",
        "\n",
        "\n",
        "  plt.figure(figsize=(15, 5))\n",
        "\n",
        "  plt.subplot(1,3,1)\n",
        "  plt.plot(epochs, train_loss, 'b', label='Training cat. cross-entropy')\n",
        "  plt.plot(epochs, val_loss, 'r', label='Validation cat. cross-entropy')\n",
        "  plt.title('Training and validation loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "\n",
        "\n",
        "  plt.subplot(1,3,2)\n",
        "  plt.plot(epochs, train_acc, 'b', label='Training accuracy')\n",
        "  plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
        "  plt.title('Training and validation accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Categorical accuracy')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.subplot(1,3,3)\n",
        "  plt.plot(epochs, train_tp, 'b', label='Training TP')\n",
        "  plt.plot(epochs, val_tp, 'r', label='Validation TP')\n",
        "  plt.title('Training and validation true positives')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('True positives')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "plot_train_history(PETRE_fit_history.history)\n",
        "\n",
        "\n",
        "\n",
        "# Use the model to predict in the form of a 10-class probability distribution\n",
        "\n",
        "\n",
        "y_train_prob = PETREmodel.predict(X_train_std)\n",
        "\n",
        "# Select the most likely class\n",
        "y_train_pred=np.argmax(y_train_prob, axis=1)\n",
        "\n",
        "print(\"\\n The classification results on the train data:\")\n",
        "print(classification_report(y_train,y_train_pred))\n",
        "print(\"Confusion matrix (train data):\\n\", confusion_matrix(y_train,y_train_pred))\n",
        "\n",
        "\n",
        "# The classification results for the validation data\n",
        "\n",
        "y_valid_prob = PETREmodel.predict(X_valid_std)\n",
        "y_valid_pred=np.argmax(y_valid_prob, axis=1)\n",
        "print(\"\\n The classification results on the validation data:\")\n",
        "print(classification_report(y_valid,y_valid_pred))\n",
        "print(\"Confusion matrix (validation data):\\n\", confusion_matrix(y_valid,y_valid_pred))\n",
        "print(\"Confusion matrix (validation data):\\n\", np.round(confusion_matrix(y_valid,y_valid_pred)/10))\n",
        "print(\"Confusion matrix (validation data):\\n\", np.round(confusion_matrix(y_valid,y_valid_pred)/10).astype(int))\n",
        "\n",
        "\n",
        "# Plot the first X validation images, their predicted labels, and the true labels in parenthesis.\n",
        "# Color correct predictions in blue and incorrect predictions in red.\n",
        "\n",
        "\n",
        "def plot_image(i, predictions_array, true_label, img):\n",
        "    true_label, img = int(true_label[i]), img[i]\n",
        "    plt.grid(False)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(img)\n",
        "\n",
        "    predicted_label = np.argmax(predictions_array)\n",
        "    if predicted_label == true_label:\n",
        "        color = 'blue'\n",
        "    else:\n",
        "        color = 'red'\n",
        "\n",
        "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "                                100*np.max(predictions_array),\n",
        "                                class_names[true_label]),\n",
        "                                color=color, fontsize=10, loc='left')\n",
        "\n",
        "def plot_value_array(i, predictions_array, true_label):\n",
        "    true_label = int(true_label[i])\n",
        "    plt.grid(False)\n",
        "    plt.xticks(range(10))\n",
        "    plt.yticks([])\n",
        "    thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
        "    plt.ylim([0, 1])\n",
        "    predicted_label = np.argmax(predictions_array)\n",
        "\n",
        "    thisplot[predicted_label].set_color('red')\n",
        "    thisplot[true_label].set_color('blue')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "num_rows = 3\n",
        "num_cols = 3\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize=(3*2*num_cols, 2*num_rows))\n",
        "\n",
        "for i in range(num_images):\n",
        "    j = random.randint(4, 20)\n",
        "    plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "    plot_image(i*j, y_valid_prob[i*j], y_valid, X_valid_std)\n",
        "    plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
        "    plot_value_array(i*j, y_valid_prob[i*j], y_valid)\n",
        "    plt.xticks(range(10), class_names, rotation=90)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ]
}